{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token ID\n",
    "Now that we have our tokens ready, we want to give them a token ID. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It', 'was', 'two', \"o'clock\", 'in', 'the', 'morning', 'of', 'September', '5', ',', '', '1939', '.', '', 'For', 'a', 'year', '\\n', 'and', 'a', 'half', 'I', 'had', 'been', 'at', 'work', 'on', 'the', 'San', 'Francisco', '_Times_', '.', '', 'I', 'had', '\\n', 'come', 'there', 'immediately', 'after', 'finishing', 'my', \"year's\", 'course', 'at', 'the', 'army', '\\n', \"officers'\", 'flying', 'school', 'at', 'San', 'Antonio', ',', '', 'on', 'the', 'chance', 'that', 'my', 'work', '\\n', 'would', 'lead', 'me', 'into', 'enough', 'tong', 'wars', 'and', 'exciting', 'murder', 'mysteries', 'to', '\\n', 'make', 'life', 'interesting', '.', '', '\\n', '', '\\n', 'The', 'morning', 'edition', 'had', 'just', 'been', '\"put', 'to', 'bed\"', 'and', 'I', 'was', 'starting', 'out', '\\n', 'of', 'the', 'office', 'when', 'the', 'night', 'editor', 'called', 'me', 'to', 'meet', 'a', 'visitor', 'who', 'had', '\\n', 'just', 'come', 'in', '.', '', 'The', 'stranger', 'came', 'forward', 'quickly', '.', '', 'Roughly', 'clad', 'in', 'blue', '\\n', 'shirt', 'and', 'overalls', ',', '', 'boots', ',', '', 'and', 'Stetson', ',', '', 'he', 'had', 'the', 'bronze', 'skin', ',', '', 'clear', '\\n', 'eyes', ',', '', 'and', 'smooth', 'movements', 'of', 'one', 'who', 'has', 'spent', 'his', 'life', 'out-of-doors', '.', '', '\\n', '', '\\n', 'He', 'stopped', 'before', 'me', 'and', 'held', 'out', 'his', 'hand', 'with', 'a', 'pleasant', 'smile', '.', '', 'I', 'saw', '\\n', 'that', 'his', 'hair', 'was', 'gray;', 'he', 'was', 'a', 'little', 'older', 'than', 'I', 'had', 'thought', 'at', '\\n', 'first--fifty', ',', '', 'perhaps', '.', '', 'I', 'liked', 'the', 'fellow', 'instinctively', '.', '', '\\n', '', '\\n', '\"Robert', 'Barrett', '?', '\"', 'he', 'questioned', 'in', 'a', 'pleasant', 'drawl', '.', '', 'I', 'nodded', '.', '', '\\n', '', '\\n', '\"I\\'m', 'Bill', 'Johnson', ',', '\"', 'he', 'said', 'briefly', '.', '', '\"I', 'want', 'to', 'see', 'you', '.', '', 'Secret', 'Service', '\\n', 'business', '.', '', '_Sabe', '?', '_\"', 'He', 'let', 'me', 'glimpse', 'a', 'badge', ',', '', 'and', 'we', 'walked', 'out', 'into', '\\n', 'the', 'night', '.', '', 'As', 'we', 'started', 'down', 'the', 'silent', 'street', 'it', 'occurred', 'to', 'me', 'that', '\\n', 'I', 'had', 'heard', 'of', 'this', 'man', 'before', '.', '', '\\n', '', '\\n', '\"Are', 'you', 'the', 'William', 'Johnson', 'who', 'unearthed', 'the', 'radio', 'station', 'of', 'the', '\\n', 'revolutionaries', 'in', 'Mexico', 'in', '1917', '?', '\"', '\\n', '', '\\n', '\"I', 'guess', 'so', '.', '', \"I've\", 'been', 'in', 'Mexico', 'thirty', 'years', ',', '', 'and', \"I've\", 'helped', 'Uncle', '\\n', 'Sam', 'out', 'a', 'time', 'or', 'two', '.', '', \"It's\", 'a', 'case', 'like', 'that', 'one', ',', '', 'or', 'worse', ',', '', 'that', \"I'm\", 'up', '\\n', 'here', 'to', 'see', 'about', 'now', '.', '', 'I', 'need', 'a', 'partner', '.', '', \"I've\", 'been', 'told', 'about', 'you', '.', '', 'Are', '\\n', 'you', 'game', 'for', 'a', 'little', 'adventure', '?', '\"', '\\n', '', '\\n', '\"You\\'ve', 'found', 'your', 'man', '.', '\"', '\\n', '', '\\n', '\"They', 'call', 'you', \"'Tiger\", 'Bob', 'Barrett', ',', \"'\", \"don't\", 'they', '?', '\"', 'he', 'said', 'irrelevantly', '.', '', '\\n', '', '\\n', '\"I', 'used', 'to', 'play', 'football', '.', '\"', '\\n', '', '\\n', 'He', 'laughed', '.', '', 'I', 'have', 'always', 'been', 'sensible', 'about', 'that', 'nickname', '.', '', '\\n', '', '\\n', '\"Well', ',', '', \"here's\", 'the', 'situation', '.', '', \"I've\", 'been', 'at', \"Vernon's\", 'mine', 'in', 'Durango', ',', '', '\\n', 'Mexico', '.', '', 'Called', 'El', 'Tigre', '.', '', 'Gold', 'and', 'thorium', '.', '', \"There's\", 'a', 'little', 'mystery--\"']\n"
     ]
    }
   ],
   "source": [
    "# Loading our tokens\n",
    "token_file_path = 'files/tokens.txt'\n",
    "\n",
    "with open(\"files/tokens.txt\", \"rb\") as file:\n",
    "    loaded_tokenized_text = pickle.load(file)\n",
    "\n",
    "print(loaded_tokenized_text[:500])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our tokens ready, we can assign them a token id. We can do so using the following steps:\n",
    "1. Create a set of tokens (since we only want the unique tokens. Duplicate tokens should have the same token ID)\n",
    "2. Use the enumerte method to generate token IDs\n",
    "3. Generate a vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": 0\n",
      "\n",
      ": 1\n",
      "!: 2\n",
      "\": 3\n",
      "\"--the: 4\n",
      "\"--well: 5\n",
      "\"And: 6\n",
      "\"Are: 7\n",
      "\"Aw: 8\n",
      "\"Bob: 9\n",
      "\"But: 10\n",
      "\"Camel-back\": 11\n",
      "\"Coming: 12\n",
      "\"Crawl: 13\n",
      "\"Demons: 14\n",
      "\"Drop: 15\n",
      "\"Ellen: 16\n",
      "\"Forward: 17\n",
      "\"Gas: 18\n",
      "\"Get: 19\n",
      "\"Good: 20\n",
      "\"He: 21\n",
      "\"Hey: 22\n",
      "\"Howdy: 23\n",
      "\"Huh: 24\n",
      "\"Hustle: 25\n",
      "\"I: 26\n",
      "\"I'll: 27\n",
      "\"I'm: 28\n",
      "\"I've: 29\n",
      "\"It: 30\n",
      "\"It's: 31\n",
      "\"It's--er--a: 32\n",
      "\"Modified: 33\n",
      "\"Move: 34\n",
      "\"No: 35\n",
      "\"Now: 36\n",
      "\"Old: 37\n",
      "\"One: 38\n",
      "\"P-p-p-p-pocket: 39\n",
      "\"Pablo: 40\n",
      "\"Plans: 41\n",
      "\"Robert: 42\n",
      "\"Say: 43\n",
      "\"Something: 44\n",
      "\"That: 45\n",
      "\"That's: 46\n",
      "\"The: 47\n",
      "\"Then: 48\n",
      "\"There's: 49\n"
     ]
    }
   ],
   "source": [
    "unique_tokens = sorted(set(loaded_tokenized_text))\n",
    "token_id = {token:id for id, token in enumerate(unique_tokens)}\n",
    "\n",
    "for element, id in list(token_id.items())[:50]:\n",
    "    print(f\"{element}: {id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
